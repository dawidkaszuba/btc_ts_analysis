---
title: "Analiza cen Bitcoina z wykorzystaniem metod jednowymiarowych szeregów czasowych"
author: "Dawid Kaszuba, Marek Falkowski, Maja Chrzan"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: cerulean
    highlight: espresso
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



```{r, include=FALSE}
library(tseries)
library(dplyr)
library(xts)
library(readr)
library(lubridate)
library(TSA)
library(forecast)
library(readr)
library(kableExtra)
library(zoo)
```

```{r, include=FALSE}
prices <- read_csv("bitcoin_2010-07-27_2024-04-25.csv")

data <- prices[order(prices$Start), ]
```


```{r}
prices_ts_xts <- xts(data$Close,data$Start)
prices_training <- prices_ts_xts['2010-07-27/2012-12-31']
```

# Cel Analizy (Kaszuba)


Celem niniejszej analizy jest zbadanie i zrozumienie charakterystyki jednowymiarowego szeregu czasowego cen Bitcoina. Analiza będzie obejmować:

1. **Analizę eksploracyjną danych:**
    - Wizualizacja danych, aby zrozumieć ogólny trend, sezonowość i potencjalne anomalie w cenach Bitcoina.

2. **Dekompozycję szeregu czasowego:**
    - Rozkład szeregu na komponenty trendu, sezonowości i losowe (residualne) za pomocą klasycznej dekompozycji.

3. **Testy stacjonarności:**
    - Przeprowadzenie testów stacjonarności, takich jak test Augmented Dickey-Fuller (ADF), aby określić, czy szereg czasowy jest stacjonarny.

4. **Modelowanie i prognozowanie:**
    - Wybór odpowiedniego modelu do prognozowania przyszłych cen Bitcoina.
    - Ocena dokładności modelu prognozowania za pomocą metryk błędu prognozy

5. **Interpretacja wyników:**
    - Wnioskowanie na podstawie wyników analizy i modelowania, w tym zrozumienie wpływu różnych czynników na zmienność cen Bitcoina.



# Źródło danych, opis i charakterystyka (Kaszuba)

<div style="text-align: justify;">
  <p>Dane pochodzą ze strony internetowej: https://www.kaggle.com/datasets/priyamchoksi/bitcoin-historical-prices-and-activity-2010-2024. Struktura badanego pliku wygląda następująco:
  </p>
</div>


```{r}
head(data)

```


# Prezentacja graficzna zbioru danych (Kaszuba)

<div style="text-align: justify;">
Poniżej przedstawiono graficzną analizę danych dotyczących cen Bitcoina za okres od lipca 2010 roku do grudnia 2012 roku. Na wykresie obserwacjemy ogólny trend wzrostowy, można doszukać się również sezonowych wzorców czy nawet anomalii.
</div>


```{r}
plot(prices_training,
     main = "Ceny Bitcoina w latach 2010-2012",
     xlab = "",  
     ylab = "Cena [USD]")
```

# Analiza-interpretacja wyników


## Interpretacja funkcji acf oraz pacf (Chrzan)


```{r}
acf(prices_training, main = "Autokorelacja Cen Bitcoina")
```
```{r}
Pacf(prices_training)
```
<div style="text-align: justify;">
  <p> 
  Autokorelacje są wysokie i stopniowo maleją w miarę wzrostu opóźnienia, nie spadając szybko do zera, co sugeruje, że ceny Bitcoina wykazują długookresową zależność z obecnością długoterminowych trendów lub sezonowości w danych. Wiedząc, że linie przerywane oznaczają granice krytyczne dla istotności statystycznej, większość wartości autokorelacji jest powyżej owych granic 95%, co oznacza, że autokorelacje są statystycznie istotne.
  </p>
  <p> 
  Dla częściowej autokorelacji, pierwsza wartość częściowej autokorelacji jest blisko 1, co oznacza silną bezpośrednią zależność między cenami z okresu t i t-1. Kolejne wartości PACF spadają szybko do zera i większość z nich mieści się w granicach krytycznych, co sugeruje, że większość istotnej autokorelacji w danych można wyjaśnić przez zależności z pierwszym opóźnieniem. Brak istotnych wartości PACF dla wyższych opóźnień sugeruje, że dalsze opóźnienia nie wnoszą dodatkowych informacji poza tym, co jest wyjaśniane przez pierwsze opóźnienie.
  </p>
  <p> Wnioski z wykresów:</p>
  <p>
  Biorąc pod uwagę wyniki ACF i PACF, dobrym wyborem dla modelu ARIMA może być model z jednym opóźnieniem w części autoregresyjnej (AR) i bez opóźnień w części różnicującej (I) oraz średniej ruchomej (MA), czyli model ARIMA(1,0,0). Jednak byłby to model prosty, który mógłby nie uchwycić wszystkich wzorców. Dobrym pomysłem będzie wtczttabue wartiści kryteriów informacyjnych AIC/BIC dla bardziej złożonego modelu. Dodatkowo wysokie wartości ACF mogą sugerować obecność trendów lub sezonowości w danych, co należy wziąć pod uwagę przy dalszym modelowaniu.
  </p>
  <p>
  Chociaż ACF pokazuje wysokie autokorelacje na wyższych opóźnieniach, PACF wskazuje, że te korelacje mogą być wyjaśnione przez pierwsze opóźnienie. Jeśli zależy nam na modelowaniu zmienności cen, warto rozważyć model GARCH, który lepiej uchwyci zmienność w czasie.
  </p>
</div>


## Dekomozycja (Kaszuba)

```{r}
attr(prices_training, 'frequency') <- 365  
plot(decompose(as.ts(prices_training)))
```
<div style="text-align: justify;">
  <p> 
    Górny panel wykresu pokazuje oryginalny szereg czasowy cen Bitcoina.Widać, że szereg czasowy ma wyraźny wzrost w okolicach  pkt 2.0 na osi czasu, po którym następuje spadek.
  </p>
  <p>
    Wykres trendu pokazuje długoterminowy ruch w danych. Widać, że początkowo trend jest prawie poziomy, potem zaczyna rosnąć i osiąga szczyt w okolicach 2.2 na osi czasu. Po tym punkcie trend zaczyna spadać, a następnie znów się podnosi.
  </p>
  <p>
    Trzeci panel pokazuje komponent sezonowy, który reprezentuje powtarzające się wzorce w danych. Wykres sezonowy wykazuje wyraźne oscylacje, które sugerują powtarzalne wzorce.
  </p>
  <p>
    Dolny panel przedstawia komponent losowy, który zawiera te elementy danych, które nie mogą być wyjaśnione przez komponenty trendu ani sezonowości. Mimo to, widać pewne wzorce, które mogą sugerować obecność dodatkowych sezonowych efektów lub innych regularności nie wychwyconych w pełni przez komponent sezonowy.
  </p>
</div>


## Wariancja dla poszczególnych miesięcy (Kaszuba)

```{r}
filtered_data <- subset(prices, Start >= as.Date("2010-07-27") & Start <= as.Date("2012-12-31"))

data_monthly <- split(filtered_data$Close, format(filtered_data$Start, "%Y-%m"))
variances <- sapply(data_monthly, var)
plot(1:length(variances), variances, type = "l", xlab = "", ylab = "", main = "Wariancja w Czasie", xaxt = "n")
axis(1, at = 1:length(variances), labels = names(variances))
```
<div style="text-align: justify;">
  <p>
    Wykres pokazuje, że zmienność (wariancja) cen Bitcoina nie jest stała w czasie. Okresy wysokiej zmienności są przeplatane okresami względnie niskiej zmienności.
    Szczyty wariancji wskazują na występowanie nagłych, dużych zmian cen. Te szoki mogą być wynikiem zewnętrznych wydarzeń lub fundamentalnych zmian na rynku kryptowalut.
    Powyższy wykres świadczy o tym, że szereg czasowy w swojej pierwotnej wersji jest szeregiem niestacjonarnym.
  </p>
<div>



## Test stacjonarności Dickeya-Fullera (Kaszuba)


```{r, warning=FALSE}
adf.test(prices_training)
```
<p>
Testowa statystyka Dickeya-Fullera (-2.1212) jest większa od wartości krytycznej na poziomie istotności 0.05. Oznacza to, że nie ma wystarczających dowodów, aby odrzucić hipotezę zerową (hipoteza o niestacjonarności) na rzecz hipotezy alternatywnej.
Zgodnie z alternatywną hipotezą, którą testuje test Dickeya-Fullera, wynik sugeruje, że szereg czasowy jest niestacjonarny. W skrócie, wynik testu sugeruje, że nie ma wystarczających dowodów, aby odrzucić hipotezę o niestacjonarności szeregu czasowego.
</p>



## Model ARIMA (Kaszuba)


1. **Analizę eksploracyjną danych (EDA):**

Na podstawie analizy wariancji cen Bitcoina w okresie od lipca 2010 roku do grudnia 2012 roku, testów stacjonarności, przeprowadzonej dekompozycji klasycznej model ARIMA (AutoRegressive Integrated Moving Average) wydaje się być odpowiednim wyborem do dopasowania i prognozowania powyższego szeregu czasowego. Poniżej przedstawiono uzasadnienie tego wyboru:

1. **Niestacjonarność Danych**:
    - Wykres wariancji wskazuje, że szereg czasowy cen Bitcoina w pierwotnej formie jest niestacjonarny. ARIMA jest skuteczny w modelowaniu niestacjonarnych danych poprzez zastosowanie różnicowania, co pozwala przekształcić niestacjonarny szereg czasowy w stacjonarny.

2. **Uwzględnienie Zmienności**:
    - Mimo że występuje zmienność, ARIMA może dobrze dopasować się do danych po transformacjach stabilizujących wariancję (np. różnicowanie logarytmiczne), co pozwala na uchwycenie istotnych wzorców w danych.

3. **Elastyczność Modelu**:
    - Model ARIMA łączy autoregresję (AR), różnicowanie (I) i średnią ruchomą (MA), co daje dużą elastyczność w dopasowywaniu różnych typów szeregów czasowych. Może uchwycić zarówno krótkoterminowe zależności, jak i długoterminowe trendy po odpowiednich transformacjach.

### dopasowanie modelu (Kaszuba)

Model bez przekształceń ze względu na występującą zmienną wariancję

```{r, include=TRUE}
arima_model <- auto.arima(prices_training)
summary(arima_model)
```
Model z przekształceniami ze względu na występującą zmienną wariancję:

```{r, include=TRUE}
arima_model_lambda <- auto.arima(prices_training, lambda="auto")
summary(arima_model_lambda)
```



Wybrano pierwszą wersję modelu ARIMA(2,1,2) 



Statystyki Modelu:

- sigma^2 = 0.3704 - Jest to szacowana wariancja błędu modelu. Niska wartość wskazuje na niską zmienność reszt modelu, co jest korzystne
- log likelihood = -817.25 - Wartość logarytmu funkcji wiarygodności jest używana do oceny dopasowania modelu. Im bliżej zera, tym lepiej. Wartość ta sugeruje, że model dobrze pasuje do danych
- AIC = 1644.49 - Kryterium informacyjne Akaike uwzględnia zarówno dopasowanie modelu, jak i jego złożoność. Im niższa wartość, tym lepiej
- Niższe wartości AIC i BIC wskazują na lepsze dopasowanie modelu przy umiarkowanej złożoności.


Miary błędu modelu:

- ME (Mean Error) = 0.0153 - Średni błąd sugeruje, że przewidywania modelu są blisko rzeczywistych wartości
- RMSE (Root Mean Squared Error): 0.6069 - Wartość ta jest miarą średniej różnicy między przewidywanymi a rzeczywistymi wartościami, wskazującą na dobrą jakość dopasowania modelu
- MAE (Mean Absolute Error): 0.2341 - Średni błąd bezwzględny wskazuje na przeciętną wielkość błędu przewidywania modelu
- MPE (Mean Percentage Error): 0.3517% - Średni błąd procentowy sugeruje, że przewidywania są blisko rzeczywistych wartości.
- MAPE (Mean Absolute Percentage Error): 4.4191% - Średni bezwzględny błąd procentowy wskazuje na przeciętną wielkość odchylenia przewidywań od rzeczywistych wartości.
- MASE (Mean Absolute Scaled Error): 0.0404 - Jest to ustandaryzowany średni błąd bezwzględny, który porównuje błąd modelu ARIMA z błędem modelu bazowego. Niska wartość sugeruje dobrą jakość modelu.
- ACF1 (Autocorrelation Function): 0.0017 - Pierwszy współczynnik autokorelacji wskazuje na brak silnej korelacji między obserwacją, a obserwacją poprzednią.


### reszty modelu (Kaszuba)

```{r}
par(mfrow = c(2, 2))
plot(arima_model$residuals, main = "Reszty modelu ARIMA", ylab = "Reszty")
acf(arima_model$residuals, main = "ACF reszt")
pacf(arima_model$residuals, main = "PACF reszt")
qqnorm(arima_model$residuals)
qqline(arima_model$residuals)

par(mfrow = c(1, 1))
residuals <- arima_model$residuals
mean_residuals <- mean(residuals)
sd_residuals <- sd(residuals)

hist(residuals, breaks=30, freq=FALSE, main="Histogram reszt modelu ARIMA", xlab="Reszty")

x_vals <- seq(min(residuals), max(residuals), length=150)
y_vals <- dnorm(x_vals, mean=mean_residuals, sd=sd_residuals)
lines(x_vals, y_vals, col="blue", lwd=2)
```


```{r}
shapiro.test(arima_model$residuals)
summary(arima_model$residuals)
```
<div style="text-align: justify;">
  <p>
    Wynik testu normalności Shapiro-Wilka sugeruje, że reszty modelu nie pochodzą z rozkładu normalnego, ponieważ p-value jest znacząco mniejsze niż poziom istotności 0.05. Oznacza to, że nie ma wystarczających dowodów na to, aby odrzucić hipotezę o nie-normalności rozkładu reszt.
  </p>
</div>



<div style="text-align: justify;">
  <p>
     Histogram reszt sugeruje, że reszty są symetryczne i skupiają się wokół zera, ale mogą nie być idealnie normalnie rozłożone. Zarówno ACF, jak i PACF wskazują na obecność istotnych autokorelacji, co sugeruje, że model ARIMA nie uchwycił wszystkich wzorców w danych. Istotne autokorelacje mogą wskazywać na potrzebę bardziej złożonego model. Wykres Q-Q sugeruje, że reszty są zbliżone do rozkładu normalnego, ale obecność ekstremalnych wartości sugeruje, że mogą występować pewne nietypowe obserwacje
  </p>
</div>

### prognozy (Kaszuba)

Wydaje się, że wybrany model ARIMA nie jest do końca dobrze dopasowny, jednak spróbujemy wykonać prognozy.

```{r}


prices_test <- prices_ts_xts['2013-01-01/2013-01-15']
prices_test_31 <- prices_ts_xts['2013-01-01/2013-01-31']

plot(prices_test, main="Dane rzeczywiste (zbiór testowy)")
forecast_arima <- forecast(arima_model, h = 15)
plot(forecast_arima, main="Prognoza 15-dniowa")
```

```{r}
accuracy_df <- as.data.frame(accuracy(forecast_arima, prices_test))
```
```{r}
kable(accuracy_df, caption = "Wyniki Funkcji `accuracy` dla Modelu ARIMA - 15 dni") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

```{r}
forecast_arima_31 <- forecast(arima_model, h = 31)
plot(forecast_arima_31, main="Prognoza 31-dniowa")
```
```{r}
accuracy_df_31 <- as.data.frame(accuracy(forecast_arima_31, prices_test_31))
```
```{r}
kable(accuracy_df_31, caption = "Wyniki Funkcji `accuracy` dla Modelu ARIMA - 31 dni") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

### wyniki funkcji accuracy dla prognozy 15 dniowej (Kaszuba)

zbiór treningowy:

- ME (Mean Error): 0.01530989 - Średni błąd sugeruje, że przewidywania modelu są blisko rzeczywistych wartości.
- RMSE (Root Mean Squared Error): 0.6069270 - Wartość ta jest miarą średniej różnicy między przewidywanymi a rzeczywistymi wartościami, wskazującą na dobrą jakość dopasowania modelu
- MAE (Mean Absolute Error): 0.2340858 - Średni błąd bezwzględny wskazuje na przeciętną wielkość błędu przewidywania modelu.
- MPE (Mean Percentage Error): 0.3516784% - Średni błąd procentowy sugeruje, że przewidywania są blisko rzeczywistych wartości.
- MAPE (Mean Absolute Percentage Error): 4.419052% - Średni bezwzględny błąd procentowy wskazuje na przeciętną wielkość odchylenia przewidywań od rzeczywistych wartości.
- MASE (Mean Absolute Scaled Error): 1.042100 - Jest to ustandaryzowany średni błąd bezwzględny, który porównuje błąd modelu ARIMA z błędem modelu bazowego. Niska wartość sugeruje dobrą jakość modelu.
- ACF1 (Autocorrelation Function): 0.00173673 - Pierwszy współczynnik autokorelacji wskazuje na brak silnej korelacji między obserwacją a obserwacją poprzednią.

zbiór testowy:

- ME (Mean Error): 0.27863654 - Średni błąd sugeruje, że przewidywania modelu dla zbioru testowego są nieco dalej od rzeczywistych wartości w porównaniu do zbioru treningowego.
- RMSE (Root Mean Squared Error): 0.4618174 - Wartość ta jest miarą średniej różnicy między przewidywanymi a rzeczywistymi wartościami dla zbioru testowego.
- MAE (Mean Absolute Error): 0.3622988 - Średni błąd bezwzględny wskazuje na przeciętną wielkość błędu przewidywania modelu dla zbioru testowego.
- MPE (Mean Percentage Error): 1.9526791% - Średni błąd procentowy dla zbioru testowego sugeruje, że przewidywania są nieco dalej od rzeczywistych wartości w porównaniu do zbioru treningowego.
- MAPE (Mean Absolute Percentage Error): 2.580064% - Średni bezwzględny błąd procentowy dla zbioru testowego wskazuje na przeciętną wielkość odchylenia przewidywań od rzeczywistych wartości.
- MASE (Mean Absolute Scaled Error): 1.612878 - Jest to ustandaryzowany średni błąd bezwzględny dla zbioru testowego, który porównuje błąd modelu ARIMA z błędem modelu bazowego. Podobnie jak dla zbioru treningowego, niska wartość sugeruje dobrą jakość modelu.

<div style="text-align: justify;">
  Analiza dokładności modelu ARIMA dla zbioru treningowego i testowego wskazuje na ogólnie dobre dopasowanie modelu do danych, ze stosunkowo niskimi błędami prognozowania. Jednak musimy zauważyć, że błędy dla zbioru testowego są nieco wyższe niż dla zbioru treningowego, co może sugerować, że model może mieć pewne trudności w generalizacji na nowe dane.
</div>

<div style="text-align: justify;">
  Widać również, że wybrany model nie radzi sobie z większym horyzontem prognoz, a błędy dla zbioru testowego są jeszcze większe niż w przypadku horyzontu 15 dniowego.
</div>


# Porównania wyników dla różnych zbiorów (szeregów) lub metod lub narzędzi

<div style="text-align: justify;">
<p>(Kaszuba)</p>
  W analizie porównano dwa modele ARIMA(2,1,2) zastosowane do zbioru treningowego "prices_training". Pierwszy model nie uwzględniał transformacji Box-Coxa, podczas gdy drugi model ją zastosował.

Pierwszy model ARIMA wykazał znaczące wartości parametrów autoregresji i średniej ruchomej, co sugeruje, że dobrze odwzorowuje strukturę danych. Estymowana wariancja błędu w tym modelu była niska, co jest pozytywnym wskaźnikiem, ponieważ niska zmienność reszt oznacza lepsze dopasowanie modelu. Logarytm funkcji wiarygodności oraz wartości kryteriów AIC i BIC również wskazywały na lepsze dopasowanie tego modelu w porównaniu do drugiego. Miary błędów prognozowania, takie jak średni błąd (ME), średni błąd kwadratowy (RMSE), średni błąd bezwzględny (MAE) i średni bezwzględny błąd procentowy (MAPE), były niskie, co potwierdza, że model dobrze przewiduje wartości czasowe.

Drugi model ARIMA, który zastosował transformację Box-Coxa, wprowadził pewne zmiany w wartościach współczynników. Jednak estymowana wariancja błędu była wyższa, co sugeruje gorsze dopasowanie. Wyższe wartości log likelihood, AIC i BIC w porównaniu do pierwszego modelu również wskazywały na słabsze dopasowanie. Miary błędów prognozowania były wyższe, co sugeruje, że ten model jest mniej dokładny.

W ostatecznym rozrachunku, wybrano pierwszy model ARIMA(2,1,2) bez transformacji Box-Coxa, ponieważ lepiej dopasowuje się do danych i ma niższe błędy prognozowania.  Mimo dobrego dopasowania do danych treningowych, model miał pewne trudności z generalizacją na nowe dane, co wskazywały nieco wyższe błędy dla zbioru testowego. Ogólnie rzecz biorąc, model ARIMA bez transformacji okazał się bardziej odpowiedni do prognozowania tego szeregu czasowego.
</div>

# Podsumowanie-wniosek

<div style="text-align: justify;">
  #todo
</div>
